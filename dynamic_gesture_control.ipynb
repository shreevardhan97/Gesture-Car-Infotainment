{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def collect_gesture_data(gesture_name, num_sequences, sequence_length, capture_duration):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    for sequence_num in range(num_sequences):\n",
    "        print(f'Collecting sequence {sequence_num} for gesture {gesture_name}')\n",
    "        sequence = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process the frame\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame_rgb)\n",
    "\n",
    "            # Draw the hand landmarks on the frame\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp.solutions.drawing_utils.draw_landmarks(\n",
    "                        frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    landmarks = [[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]\n",
    "                    sequence.append(landmarks)\n",
    "            \n",
    "            cv2.imshow('Collecting Gestures', frame)\n",
    "            if time.time() - start_time > capture_duration:\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # After the loop, trim or pad the sequence to have a consistent length\n",
    "        sequence = sequence[:sequence_length] if len(sequence) > sequence_length else sequence + [[0, 0, 0]] * (sequence_length - len(sequence))\n",
    "        \n",
    "        # Save sequences to a file\n",
    "        sequence_path = os.path.join('gestures_dataset', gesture_name, f'seq_{sequence_num}.json')\n",
    "        os.makedirs(os.path.dirname(sequence_path), exist_ok=True)\n",
    "        with open(sequence_path, 'w') as f:\n",
    "            json.dump(sequence, f)\n",
    "\n",
    "        print(f'Saved sequence {sequence_num} for gesture {gesture_name}')\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Collect data for 'swipe left' and 'swipe right'\n",
    "# Assuming we want to capture each gesture for 2 seconds\n",
    "collect_gesture_data('swipe_left', num_sequences=30, sequence_length=30, capture_duration=2)\n",
    "collect_gesture_data('swipe_right', num_sequences=30, sequence_length=30, capture_duration=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(gesture_names, sequence_length, num_landmarks=21, num_coordinates=3):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for gesture_name in gesture_names:\n",
    "        data_path = os.path.join('gestures_dataset', gesture_name)\n",
    "        class_index = gesture_names.index(gesture_name)\n",
    "        \n",
    "        for sequence_file in os.listdir(data_path):\n",
    "            with open(os.path.join(data_path, sequence_file), 'r') as f:\n",
    "                sequence = json.load(f)\n",
    "                \n",
    "                # Pad each frame to have a consistent number of landmarks with a consistent number of coordinates\n",
    "                padded_sequence = []\n",
    "                for frame in sequence:\n",
    "                    # Ensure frame has a consistent number of landmarks\n",
    "                    if len(frame) > num_landmarks:\n",
    "                        frame = frame[:num_landmarks]\n",
    "                    elif len(frame) < num_landmarks:\n",
    "                        frame.extend([[0, 0, 0] for _ in range(num_landmarks - len(frame))])\n",
    "                    \n",
    "                    # Ensure each landmark has a consistent number of coordinates\n",
    "                    padded_frame = []\n",
    "                    for landmark in frame:\n",
    "                        if isinstance(landmark, list):\n",
    "                            if len(landmark) > num_coordinates:\n",
    "                                landmark = landmark[:num_coordinates]\n",
    "                            elif len(landmark) < num_coordinates:\n",
    "                                landmark.extend([0] * (num_coordinates - len(landmark)))\n",
    "                        else:\n",
    "                            # If landmark is not a list, it's an error in data structure\n",
    "                            landmark = [0] * num_coordinates\n",
    "                        padded_frame.append(landmark)\n",
    "                    padded_sequence.append(padded_frame)\n",
    "                \n",
    "                # Ensure the sequence has a consistent number of frames\n",
    "                if len(padded_sequence) > sequence_length:\n",
    "                    padded_sequence = padded_sequence[:sequence_length]\n",
    "                elif len(padded_sequence) < sequence_length:\n",
    "                    padded_sequence.extend([[[0] * num_coordinates for _ in range(num_landmarks)] for _ in range(sequence_length - len(padded_sequence))])\n",
    "                \n",
    "                sequences.append(padded_sequence)\n",
    "                labels.append(class_index)\n",
    "\n",
    "    sequences_np = np.zeros((len(sequences), sequence_length, num_landmarks, num_coordinates), dtype=np.float32)\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        sequences_np[i] = np.array(sequence, dtype=np.float32)\n",
    "\n",
    "    return sequences_np, np.array(labels)\n",
    "\n",
    "gesture_names = ['swipe_left', 'swipe_right']\n",
    "sequences, labels = load_data(gesture_names, sequence_length=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels = to_categorical(labels, num_classes=len(gesture_names))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = create_model(sequence_length=30, num_features=63)  # 63 features (21 landmarks * 3 coordinates)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model for later use\n",
    "model.save('swipe_gesture_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
